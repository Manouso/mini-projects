{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99e4ba62",
   "metadata": {},
   "source": [
    "# Advanced Transfer Learning with ResNet18 on CIFAR-10\n",
    "\n",
    "This notebook demonstrates advanced transfer learning using a pretrained ResNet18 model on the CIFAR-10 dataset. We'll replace the classifier head and fine-tune the model for better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6540f1ab",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfad16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f171d8e4",
   "metadata": {},
   "source": [
    "## 2. Load and Preprocess CIFAR-10 Dataset + Data Augmentation\n",
    "\n",
    "CIFAR-10 consists of 60,000 32x32 color images in 10 classes. We'll apply extensive data augmentation including random cropping, flipping, rotation, color jittering, affine transformations, perspective distortion, and random erasing to improve model generalization and robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30ac5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transforms for training and validation with enhanced augmentation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),  # First resize to larger size 256x256 (because now we can crop out image)\n",
    "        transforms.RandomCrop(224),  # Random crop to 224x224\n",
    "        transforms.RandomHorizontalFlip(),  # Horizontal flip\n",
    "        transforms.RandomVerticalFlip(p=0.1),  # Occasional vertical flip\n",
    "        transforms.RandomRotation(15),  # Random rotation up to 15 degrees\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color adjustments\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),  # Translation and scaling\n",
    "        transforms.RandomPerspective(distortion_scale=0.2, p=0.5),  # Perspective distortion\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3))  # Random erasing (cutout)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),  # Resize smaller images to 256x256 to prepare for center cropping\n",
    "        transforms.CenterCrop(224),  # Crop the center 224x224 region to match ResNet input size\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "full_train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=data_transforms['train'])\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=data_transforms['val'])\n",
    "\n",
    "# For Stratified K-Fold tuning, keep full_train_dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "# Class names\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "print(f\"Full training dataset size: {len(full_train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "print(f\"Classes: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f9f8a8",
   "metadata": {},
   "source": [
    "## 3. Load Pretrained ResNet18 Model\n",
    "\n",
    "We'll load the pretrained ResNet18 model from torchvision. Since CIFAR-10 images are 32x32 and ResNet expects 224x224, we've already resized them in the transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7abd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained ResNet18 model\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Print model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcc1839",
   "metadata": {},
   "source": [
    "## 4. Set Up Training Components\n",
    "\n",
    "Define the loss function, optimizer, and move the model to the appropriate device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b8497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs=20, patience=5):\n",
    "    start = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_running_corrects = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_acc = val_running_corrects.double() / len(val_loader.dataset)\n",
    "\n",
    "        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} | Val Acc: {val_acc:.4f}')\n",
    "\n",
    "        # Check for improvement\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        # Early stopping\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f'Early stopping at epoch {epoch}')\n",
    "            break\n",
    "        \n",
    "    time_elapsed = time.time() - start\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085b7356",
   "metadata": {},
   "source": [
    "## 5. Random Search Hyperparameter Tuning for Custom Classifier\n",
    "\n",
    "We'll perform **random search** hyperparameter tuning to find the optimal classifier architecture. Random search is more efficient than grid search and often finds better hyperparameters by exploring the search space more effectively.\n",
    "\n",
    "**Random search advantages:**\n",
    "- Tests 10 random combinations instead of all possible combinations (much faster)\n",
    "- More likely to find good hyperparameters in high-dimensional spaces\n",
    "- Can explore continuous ranges more effectively\n",
    "\n",
    "Each trial uses **early stopping with patience=3** and **GPU acceleration** for maximum efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb6524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search hyperparameter tuning for the custom classifier with early stopping\n",
    "\n",
    "def create_classifier(num_ftrs, hidden_dims, dropout_rates, device):\n",
    "    \n",
    "    layers = []\n",
    "    in_features = num_ftrs\n",
    "\n",
    "    for i, out_features in enumerate(hidden_dims):\n",
    "        layers.append(nn.Linear(in_features, out_features).to(device))\n",
    "        layers.append(nn.ReLU())\n",
    "        if i < len(dropout_rates):\n",
    "            layers.append(nn.Dropout(dropout_rates[i]))\n",
    "        in_features = out_features\n",
    "\n",
    "    layers.append(nn.Linear(in_features, 10).to(device))  # 10 classes for CIFAR-10\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def tune_classifier_hyperparameters(model, full_train_dataset, num_trials=10, max_epochs=5):\n",
    "  \n",
    "\n",
    "    num_ftrs = model.fc.in_features\n",
    "\n",
    "    # Define hyperparameter search spaces for random sampling\n",
    "    hidden_dims_options = [\n",
    "        [512, 256],        # 2 hidden layers medium\n",
    "        [1024, 512, 256],  # 3 hidden layers large\n",
    "        [256, 128],        # 2 hidden layers small\n",
    "\n",
    "    ]\n",
    "\n",
    "    dropout_options = [\n",
    "        [0.3, 0.2],        # Lower dropout\n",
    "        [0.5, 0.3],        # Medium dropout\n",
    "    \n",
    "        [0.3, 0.2, 0.1],   # For 3-layer networks\n",
    "        \n",
    "    ]\n",
    "\n",
    "    lr_options = [1e-4, 1e-3]  # learning rate options\n",
    "    weight_decay_options = [0,1e-4,1e-3]  # weight decay options\n",
    "\n",
    "    best_accuracy = 0.0\n",
    "    best_params = {}\n",
    "    best_model_state = None\n",
    "\n",
    "    # Get labels for stratification\n",
    "    labels = [label for _, label in full_train_dataset]\n",
    "\n",
    "    print(f\"Starting random search with {num_trials} trials using 80-20 train-validation split...\")\n",
    "\n",
    "    for trial in range(num_trials):\n",
    "        # Randomly sample hyperparameters\n",
    "        hidden_dims = random.choice(hidden_dims_options)\n",
    "\n",
    "        # Find compatible dropout options (same length as hidden_dims)\n",
    "        compatible_dropouts = [d for d in dropout_options if len(d) == len(hidden_dims)]\n",
    "        if not compatible_dropouts:\n",
    "            # Fallback to generate compatible dropout\n",
    "            dropout_rates = [np.random.uniform(0.1, 0.5) for _ in hidden_dims]\n",
    "        else:\n",
    "            dropout_rates = random.choice(compatible_dropouts)\n",
    "\n",
    "        lr = random.choice(lr_options)\n",
    "        wd = random.choice(weight_decay_options)\n",
    "\n",
    "        print(f\"\\nTrial {trial+1}/{num_trials}\")\n",
    "        print(f\"Hidden dims: {hidden_dims}, Dropout: {dropout_rates}, LR: {lr}, WD: {wd}\")\n",
    "\n",
    "        # 80-20 train-validation split\n",
    "        train_idx, val_idx = train_test_split(np.arange(len(full_train_dataset)), test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "        # Create subsets for this split\n",
    "        train_subset = Subset(full_train_dataset, train_idx)\n",
    "        val_subset = Subset(full_train_dataset, val_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_size=128, shuffle=True, num_workers=4)\n",
    "        val_loader = DataLoader(val_subset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "        # Create model for this trial\n",
    "        temp_model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1).to(device)\n",
    "        temp_model.fc = create_classifier(num_ftrs, hidden_dims, dropout_rates, device)\n",
    "\n",
    "        # Freeze all layers except classifier\n",
    "        for param in temp_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in temp_model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        # Setup optimizer and scheduler\n",
    "        optimizer = optim.AdamW(temp_model.fc.parameters(), lr=lr, weight_decay=wd)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "        # Training with early stopping for this trial\n",
    "        temp_model, best_acc = train_model(temp_model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs=max_epochs, patience=3)\n",
    "\n",
    "        # Use the best validation accuracy for this trial\n",
    "        trial_accuracy = best_acc * 100  # Convert to percentage\n",
    "        print(f\"Validation Accuracy: {trial_accuracy:.2f}%\")\n",
    "\n",
    "        if trial_accuracy > best_accuracy:\n",
    "            best_accuracy = trial_accuracy\n",
    "            best_params = {\n",
    "                'hidden_dims': hidden_dims,\n",
    "                'dropout_rates': dropout_rates,\n",
    "                'lr': lr,\n",
    "                'weight_decay': wd\n",
    "            }\n",
    "            # Save the model state\n",
    "            best_model_state = temp_model.state_dict().copy()\n",
    "\n",
    "    print(f\"\\nBest hyperparameters found:\")\n",
    "    print(f\"Hidden dimensions: {best_params['hidden_dims']}\")\n",
    "    print(f\"Dropout rates: {best_params['dropout_rates']}\")\n",
    "    print(f\"Learning rate: {best_params['lr']}\")\n",
    "    print(f\"Weight decay: {best_params['weight_decay']}\")\n",
    "    print(f\"Best validation accuracy: {best_accuracy:.2f}%\")\n",
    "\n",
    "    return best_params, best_accuracy, best_model_state\n",
    "\n",
    "# Perform hyperparameter tuning with random search using 80-20 train-validation split\n",
    "print(\"Starting random search hyperparameter tuning for the classifier...\")\n",
    "\n",
    "best_params, best_accuracy, best_model_state = tune_classifier_hyperparameters(\n",
    "    models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1), full_train_dataset, num_trials=10, max_epochs=5\n",
    ")\n",
    "\n",
    "# Create the final model with best hyperparameters\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = create_classifier(num_ftrs, best_params['hidden_dims'], best_params['dropout_rates'], device)\n",
    "model.load_state_dict(best_model_state)\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"\\nFinal model architecture: {model.fc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332acbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split full_train_dataset into train and validation\n",
    "labels = [label for _, label in full_train_dataset]\n",
    "train_idx, val_idx = train_test_split(np.arange(len(full_train_dataset)), test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "train_subset = Subset(full_train_dataset, train_idx)\n",
    "val_subset = Subset(full_train_dataset, val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=128, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_subset, batch_size=128, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5c7724",
   "metadata": {},
   "source": [
    "## 6. Freeze Model Layers\n",
    "\n",
    "We'll freeze all the convolutional layers to retain the pretrained features and only train the new classifier head initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5742cafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers except the classifier\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the classifier layers\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Verify which parameters are trainable\n",
    "trainable_params = [name for name, param in model.named_parameters() if param.requires_grad]\n",
    "print(f\"Trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469531ec",
   "metadata": {},
   "source": [
    "## 7. Train the Classifier Head\n",
    "\n",
    "Train only the new classifier head while keeping the pretrained layers frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271c097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier head\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.fc.parameters(), lr=best_params['lr'], weight_decay=best_params['weight_decay'])\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n",
    "\n",
    "model, _ = train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs=20, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093fffb1",
   "metadata": {},
   "source": [
    "## 8 Fine-Tune the Entire Model\n",
    "\n",
    "Now that the classifier is trained, we'll unfreeze all layers of the ResNet backbone and fine-tune the entire model with a lower learning rate to adapt the pretrained features to CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d592e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze all layers for full fine-tuning\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Use AdamW with lower learning rate for fine-tuning\n",
    "fine_tune_optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "fine_tune_scheduler = optim.lr_scheduler.CosineAnnealingLR(fine_tune_optimizer, T_max=20)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Fine-tune for more epochs\n",
    "model, _ = train_model(model, criterion, fine_tune_optimizer, fine_tune_scheduler, train_loader, val_loader, num_epochs=20, patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1cf8fb",
   "metadata": {},
   "source": [
    "## 9. Evaluate the Model\n",
    "\n",
    "Evaluate the fine-tuned model on the test set and compute final metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f1dd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    running_corrects = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "    accuracy = running_corrects.double() / len(dataloader.dataset)\n",
    "    return accuracy.item()\n",
    "\n",
    "# Evaluate on test set\n",
    "test_accuracy = evaluate_model(model, test_loader)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'resnet18_cifar10_transfer_learning.pth')\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# Visualize predictions on one image per class\n",
    "model.eval()\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Find one image per class\n",
    "class_indices = {}\n",
    "for idx, (img, label) in enumerate(test_dataset):\n",
    "    if label not in class_indices:\n",
    "        class_indices[label] = idx\n",
    "    if len(class_indices) == 10:\n",
    "        break\n",
    "\n",
    "for i, (class_idx, img_idx) in enumerate(class_indices.items()):\n",
    "    img, true_label = test_dataset[img_idx]\n",
    "    img_tensor = img.unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        _, pred_label = torch.max(output, 1)\n",
    "        pred_label = pred_label.item()\n",
    "    \n",
    "    # Denormalize for display\n",
    "    img = img * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1) + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    img = torch.clamp(img, 0, 1)\n",
    "    \n",
    "    axes[i].imshow(img.permute(1, 2, 0).cpu().numpy())\n",
    "    axes[i].set_title(f'True: {class_names[true_label]}\\nPred: {class_names[pred_label]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4db6dc",
   "metadata": {},
   "source": [
    "## 10. Gradient Flow Visualization\n",
    "\n",
    "Visualize the gradient flow through the network to check for vanishing or exploding gradients. This helps understand how gradients propagate during backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53b2f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grad_flow(named_parameters):\n",
    "   \n",
    "    ave_grads = []\n",
    "    max_grads = []\n",
    "    min_grads = []\n",
    "    layers = []\n",
    "\n",
    "    # Iterate through model parameters to collect gradients\n",
    "    for n, p in named_parameters:\n",
    "        if p.requires_grad and p.grad is not None and \"bias\" not in n:\n",
    "            layers.append(n)\n",
    "            ave_grads.append(p.grad.abs().mean().cpu())\n",
    "            max_grads.append(p.grad.abs().max().cpu())\n",
    "            min_grads.append(p.grad.abs().min().cpu())\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(ave_grads, alpha=0.3, color=\"b\", label=\"Average gradient\") # Blue line for average gradients\n",
    "    plt.plot(max_grads, alpha=0.3, color=\"r\", label=\"Max gradient\") # Red line for max gradients\n",
    "    plt.plot(min_grads, alpha=0.3, color=\"g\", label=\"Min gradient\") # Green line for min gradients\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\")\n",
    "    plt.xticks(range(0, len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(xmin=0, xmax=len(ave_grads))\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"Gradient magnitude\")\n",
    "    plt.title(\"Gradient Flow\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# To visualize gradient flow, we need to perform a forward and backward pass\n",
    "# Let's take a small batch from the test set\n",
    "model.eval()\n",
    "inputs, labels = next(iter(test_loader))\n",
    "inputs = inputs[:4].to(device)  # Take first 4 images\n",
    "labels = labels[:4].to(device)\n",
    "\n",
    "# Define criterion (same as used in training)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Forward pass\n",
    "outputs = model(inputs)\n",
    "loss = criterion(outputs, labels)\n",
    "\n",
    "# Backward pass to compute gradients\n",
    "loss.backward()\n",
    "\n",
    "# Plot gradient flow\n",
    "plot_grad_flow(model.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0008fb5f",
   "metadata": {},
   "source": [
    "## 11. Grad-CAM Visualization\n",
    "\n",
    "Grad-CAM (Gradient-weighted Class Activation Mapping) visualizes which parts of the input image were most important for the model's prediction. This helps understand what the model is focusing on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b9fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.feature_maps = None\n",
    "\n",
    "        # Hook to get gradients\n",
    "        def backward_hook(module, grad_input, grad_output):\n",
    "            self.gradients = grad_output[0]\n",
    "\n",
    "        # Hook to get feature maps\n",
    "        def forward_hook(module, input, output):\n",
    "            self.feature_maps = output\n",
    "\n",
    "        # Register hooks\n",
    "        self.target_layer.register_forward_hook(forward_hook)\n",
    "        self.target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "# Generate Grad-CAM\n",
    "    def generate_cam(self, input_image, target_class=None):\n",
    "\n",
    "        # Forward pass\n",
    "        self.model.eval()\n",
    "        output = self.model(input_image)\n",
    "\n",
    "        if target_class is None:\n",
    "            target_class = output.argmax(dim=1).item()\n",
    "\n",
    "        # Zero gradients\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        # Backward pass for target class\n",
    "        one_hot = torch.zeros_like(output)\n",
    "        one_hot[0][target_class] = 1\n",
    "        output.backward(gradient=one_hot, retain_graph=True)\n",
    "\n",
    "        # Get weights from gradients\n",
    "        weights = torch.mean(self.gradients, dim=[0, 2, 3])\n",
    "\n",
    "        # Generate CAM\n",
    "        cam = torch.zeros(self.feature_maps.shape[2:], dtype=torch.float32).to(self.feature_maps.device)\n",
    "        for i, w in enumerate(weights):\n",
    "            cam += w * self.feature_maps[0, i, :, :]\n",
    "\n",
    "        cam = torch.relu(cam)\n",
    "        cam = cam - cam.min()\n",
    "        cam = cam / cam.max()\n",
    "\n",
    "        return cam.detach().cpu().numpy(), target_class\n",
    "\n",
    "# Function to display Grad-CAM results\n",
    "def show_gradcam(image, mask, predicted_class, true_class, class_names):\n",
    "\n",
    "    # Convert to numpy\n",
    "    image = image.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    # Denormalize\n",
    "    image = image * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "    image = np.clip(image, 0, 1)\n",
    "\n",
    "    # Resize mask to image size\n",
    "    mask = cv2.resize(mask, (image.shape[1], image.shape[0]))\n",
    "    mask = np.uint8(255 * mask)\n",
    "\n",
    "    # Apply colormap\n",
    "    heatmap = cv2.applyColorMap(mask, cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Overlay\n",
    "    superimposed_img = heatmap * 0.4 + image * 255\n",
    "    superimposed_img = np.uint8(superimposed_img)\n",
    "\n",
    "    # Plot\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title(f'Original Image\\nTrue: {class_names[true_class]}')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    ax2.imshow(mask, cmap='jet')\n",
    "    ax2.set_title('Grad-CAM Heatmap')\n",
    "    ax2.axis('off')\n",
    "\n",
    "    ax3.imshow(superimposed_img)\n",
    "    ax3.set_title(f'Overlay\\nPredicted: {class_names[predicted_class]}')\n",
    "    ax3.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Set up Grad-CAM for ResNet18 (using the last conv layer)\n",
    "target_layer = model.layer4[1].conv2  # Last convolutional layer in ResNet18\n",
    "grad_cam = GradCAM(model, target_layer)\n",
    "\n",
    "# Visualize Grad-CAM for a few test images\n",
    "model.eval()\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Find one image per class\n",
    "class_indices = {}\n",
    "for idx, (img, label) in enumerate(test_dataset):\n",
    "    if label not in class_indices:\n",
    "        class_indices[label] = idx\n",
    "    if len(class_indices) == 10:\n",
    "        break\n",
    "\n",
    "# Generate and plot Grad-CAM for each image\n",
    "for i, (class_idx, img_idx) in enumerate(class_indices.items()):\n",
    "    img, true_label = test_dataset[img_idx]\n",
    "    img = img.unsqueeze(0).to(device)\n",
    "\n",
    "    # Generate Grad-CAM\n",
    "    cam, pred_class = grad_cam.generate_cam(img)\n",
    "\n",
    "    # Denormalize for display\n",
    "    display_img = img.squeeze(0).cpu()\n",
    "    display_img = display_img * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1) + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    display_img = torch.clamp(display_img, 0, 1)\n",
    "\n",
    "    # Resize CAM to image size\n",
    "    cam_resized = cv2.resize(cam, (display_img.shape[2], display_img.shape[1]))\n",
    "\n",
    "    # Create heatmap\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB) / 255.0\n",
    "\n",
    "    # Overlay\n",
    "    overlay = 0.4 * heatmap + 0.6 * display_img.permute(1, 2, 0).numpy()\n",
    "\n",
    "    axes[i].imshow(overlay)\n",
    "    axes[i].set_title(f'True: {class_names[true_label]}\\nPred: {class_names[pred_class]}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_env)",
   "language": "python",
   "name": "pip-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
