{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data Processing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn: Model Selection\n",
    "from sklearn.model_selection import train_test_split as tts, RandomizedSearchCV, StratifiedKFold\n",
    "\n",
    "# Scikit-learn: Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Scikit-learn: Models\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "\n",
    "# Scikit-learn: Metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "\n",
    "# Scipy distributions for RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1403c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('../../datasets/creditcard.csv') # change path if you need to\n",
    "\n",
    "# Initial Exploration\n",
    "print(\"Info about the dataset:\")\n",
    "print(\"-------------------------\")\n",
    "print(data.info())\n",
    "print(\"-------------------------\")\n",
    "print(\"How many missing values are there in each column?\")\n",
    "print(\"-------------------------\")\n",
    "print(data.isna().sum())\n",
    "print(\"-------------------------\")\n",
    "print(\"How many null values are there in each column?\")\n",
    "print(\"-------------------------\")\n",
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8272129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "# 1. Dataset Overview\n",
    "print(\"Dataset Shape:\", data.shape)\n",
    "\n",
    "# 2. Class Distribution (Imbalance Check)\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x='Class', data=data)\n",
    "plt.title('Distribution of Target Variable (Class)')\n",
    "plt.xlabel('Class (0: Non-Fraudulent, 1: Fraudulent)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "class_counts = data['Class'].value_counts()\n",
    "plt.pie(class_counts, labels=['Non-Fraud', 'Fraud'], autopct='%1.2f%%', startangle=90)\n",
    "plt.title('Class Imbalance Percentage')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nClass Distribution:\\n{class_counts}\")\n",
    "print(f\"Imbalance Ratio: {class_counts[0]/class_counts[1]:.2f}:1\")\n",
    "\n",
    "# 3. Statistical Summary\n",
    "print(\"\\nStatistical Summary of Amount and Time:\")\n",
    "print(data[['Time', 'Amount']].describe())\n",
    "\n",
    "# 4. Amount Distribution by Class\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data[data['Class']==0]['Amount'], bins=50, alpha=0.7, label='Non-Fraud')\n",
    "plt.hist(data[data['Class']==1]['Amount'], bins=50, alpha=0.7, label='Fraud')\n",
    "plt.xlabel('Transaction Amount')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Amount Distribution by Class')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x='Class', y='Amount', data=data)\n",
    "plt.title('Amount Distribution by Class (Boxplot)')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Time Distribution\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.boxplot(x='Class', y='Time', data=data)\n",
    "plt.title('Time Distribution by Class')\n",
    "plt.xlabel('Class (0: Non-Fraudulent, 1: Fraudulent)')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Top 15 Features Correlated with Fraud (Heatmap)\n",
    "v_features = [col for col in data.columns if col.startswith('V')]\n",
    "correlations = data[v_features + ['Class']].corr()['Class'].drop('Class').sort_values(key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 Features Correlated with Fraud:\")\n",
    "print(correlations.head(15))\n",
    "\n",
    "# Create correlation matrix for top 15 features + Class\n",
    "top_15_features = correlations.head(15).index.tolist()\n",
    "correlation_matrix = data[top_15_features + ['Class']].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Heatmap: Top 15 Features vs Class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5a5efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Model Pipeline\n",
    "\n",
    "# Define features and target\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "# Use stratified sampling to reduce dataset size while maintaining class distribution\n",
    "\n",
    "print(f\"Original dataset size: {len(X):,} samples\")\n",
    "\n",
    "# Sample 30% of data for faster training (stratified)\n",
    "X_sampled, _, y_sampled, _ = tts(X, y, train_size=0.3, random_state=42, stratify=y)\n",
    "print(f\"Sampled dataset size: {len(X_sampled):,} samples\")\n",
    "print(f\"Original class distribution: {y.value_counts(normalize=True).to_dict()}\")\n",
    "print(f\"Sampled class distribution: {y_sampled.value_counts(normalize=True).to_dict()}\")\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = tts(X_sampled, y_sampled, test_size=0.2, random_state=42, stratify=y_sampled)\n",
    "\n",
    "print(f\"\\nTrain set size: {len(X_train):,}\")\n",
    "print(f\"Test set size: {len(X_test):,}\")\n",
    "\n",
    "# Preprocessing Pipeline\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ])\n",
    "\n",
    "# Define the Models\n",
    "\n",
    "# Logistic Regression Pipeline\n",
    "log_clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('classifier', LogisticRegression(solver='liblinear', max_iter=1000))])\n",
    "\n",
    "# Random Forest Pipeline\n",
    "rf_clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                         ('classifier', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "# Xtreme Gradient Boosting Pipeline\n",
    "xb_clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                         ('classifier', xgb.XGBClassifier(random_state=42, n_jobs=1))])\n",
    "\n",
    "# Voting Classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('logistic', log_clf),\n",
    "        ('random_forest', rf_clf),\n",
    "        ('xgboost', xb_clf)\n",
    "    ],\n",
    "    voting='soft' # Use 'soft' voting to consider predicted probabilities\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73be2efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "# RandomizedSearch parameter grid\n",
    "param_dist_random = {\n",
    "    'logistic__classifier__C': uniform(0.1, 5),\n",
    "    'logistic__classifier__class_weight': ['balanced', {0: 1, 1: 20}],\n",
    "    'random_forest__classifier__n_estimators': randint(50, 150),\n",
    "    'random_forest__classifier__class_weight': ['balanced', 'balanced_subsample'],\n",
    "    'xgboost__classifier__n_estimators': randint(50, 150),\n",
    "    'xgboost__classifier__max_depth': randint(3, 7),\n",
    "    'xgboost__classifier__learning_rate': uniform(0.05, 0.2),\n",
    "    'xgboost__classifier__scale_pos_weight': [25, 50, 75]\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "# RandomizedSearch - broad exploration\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=voting_clf,\n",
    "    param_distributions=param_dist_random,\n",
    "    n_iter=10,\n",
    "    scoring='recall',\n",
    "    cv=skf,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Running RandomizedSearch...\")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_model_random = random_search.best_estimator_\n",
    "y_pred_random = best_model_random.predict(X_test)\n",
    "y_proba_random = best_model_random.predict_proba(X_test)[:, 1]\n",
    "\n",
    "report_random = classification_report(y_test, y_pred_random, output_dict=True)\n",
    "recall_random = report_random['1']['recall']\n",
    "f1_random = report_random['1']['f1-score']\n",
    "precision_random = report_random['1']['precision']\n",
    "\n",
    "print(f\"\\nRandomizedSearch Results:\")\n",
    "print(f\"Recall: {recall_random:.4f} | F1: {f1_random:.4f} | Precision: {precision_random:.4f}\")\n",
    "print(f\"Best params: {random_search.best_params_}\")\n",
    "\n",
    "\n",
    "# BayesianSearch - fine-tuning around RandomizedSearch best params\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Extract best values\n",
    "best_C = best_params.get('logistic__classifier__C', 1.0)\n",
    "best_rf_n_est = best_params.get('random_forest__classifier__n_estimators', 100)\n",
    "best_xgb_n_est = best_params.get('xgboost__classifier__n_estimators', 100)\n",
    "best_xgb_depth = best_params.get('xgboost__classifier__max_depth', 5)\n",
    "best_xgb_lr = best_params.get('xgboost__classifier__learning_rate', 0.1)\n",
    "best_scale_pos = best_params.get('xgboost__classifier__scale_pos_weight', 50)\n",
    "\n",
    "# Build narrow ranges around best parameters\n",
    "bayesian_param_dist = {\n",
    "    'logistic__classifier__C': Real(max(0.01, best_C * 0.5), min(10, best_C * 2), prior='log-uniform'),\n",
    "    'logistic__classifier__class_weight': Categorical(['balanced']),\n",
    "    'random_forest__classifier__n_estimators': Integer(max(50, best_rf_n_est - 30), min(200, best_rf_n_est + 30)),\n",
    "    'random_forest__classifier__class_weight': Categorical(['balanced', 'balanced_subsample']),\n",
    "    'xgboost__classifier__n_estimators': Integer(max(50, best_xgb_n_est - 30), min(200, best_xgb_n_est + 30)),\n",
    "    'xgboost__classifier__max_depth': Integer(max(2, best_xgb_depth - 2), min(10, best_xgb_depth + 2)),\n",
    "    'xgboost__classifier__learning_rate': Real(max(0.01, best_xgb_lr * 0.5), min(0.3, best_xgb_lr * 2), prior='log-uniform'),\n",
    "    'xgboost__classifier__scale_pos_weight': Integer(max(20, best_scale_pos - 25), min(150, best_scale_pos + 25))\n",
    "}\n",
    "\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=voting_clf,\n",
    "    search_spaces=bayesian_param_dist,\n",
    "    n_iter=15,\n",
    "    scoring='recall',\n",
    "    cv=skf,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nRunning Bayesian Optimization...\")\n",
    "bayes_search.fit(X_train, y_train)\n",
    "\n",
    "best_model_bayes = bayes_search.best_estimator_\n",
    "y_pred_bayes = best_model_bayes.predict(X_test)\n",
    "y_proba_bayes = best_model_bayes.predict_proba(X_test)[:, 1]\n",
    "\n",
    "report_bayes = classification_report(y_test, y_pred_bayes, output_dict=True)\n",
    "recall_bayes = report_bayes['1']['recall']\n",
    "f1_bayes = report_bayes['1']['f1-score']\n",
    "precision_bayes = report_bayes['1']['precision']\n",
    "\n",
    "# Final Comparison\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Metric':<15} {'Random':<12} {'Bayesian':<12} {'Δ':<10}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"{'Recall':<15} {recall_random:<12.4f} {recall_bayes:<12.4f} {recall_bayes-recall_random:+.4f}\")\n",
    "print(f\"{'F1-Score':<15} {f1_random:<12.4f} {f1_bayes:<12.4f} {f1_bayes-f1_random:+.4f}\")\n",
    "print(f\"{'Precision':<15} {precision_random:<12.4f} {precision_bayes:<12.4f} {precision_bayes-precision_random:+.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nConfusion Matrix (Bayesian):\")\n",
    "print(confusion_matrix(y_test, y_pred_bayes))\n",
    "print(\"\\nClassification Report (Bayesian):\")\n",
    "print(classification_report(y_test, y_pred_bayes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1354634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Analysis for  Voting Classifier\n",
    "\n",
    "# Extract feature importances from each model in the Voting Classifier\n",
    "def get_feature_importances(voting_clf, feature_names):\n",
    "    importances = {}\n",
    "    \n",
    "    for name, estimator in voting_clf.named_estimators_.items():\n",
    "        if hasattr(estimator.named_steps['classifier'], 'feature_importances_'):\n",
    "            importances[name] = estimator.named_steps['classifier'].feature_importances_\n",
    "        elif hasattr(estimator.named_steps['classifier'], 'coef_'):\n",
    "            importances[name] = np.abs(estimator.named_steps['classifier'].coef_).flatten()\n",
    "    \n",
    "    # Create a DataFrame to hold importances\n",
    "    importance_df = pd.DataFrame(importances, index=feature_names)\n",
    "    return importance_df\n",
    "\n",
    "feature_names = X.columns.tolist()\n",
    "importance_df = get_feature_importances(best_model_bayes, feature_names)\n",
    "\n",
    "# Plot feature importances\n",
    "importance_df.plot(kind='bar', figsize=(15, 7))\n",
    "plt.title('Feature Importances from Each Model in Voting Classifier')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d775c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Analysis Visualizations to identify patterns in misclassifications\n",
    "\n",
    "# Error correlation with features\n",
    "errors = X_test[y_test != y_pred_bayes]\n",
    "errors['Actual'] = y_test[y_test != y_pred_bayes]\n",
    "errors['Predicted'] = y_pred_bayes[y_test != y_pred_bayes]\n",
    "\n",
    "# Plot feature distributions for misclassified samples\n",
    "print(\"\\nError Analysis - Misclassified Samples:\")\n",
    "for feature in feature_names:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.kdeplot(data=X_test, x=feature, hue=y_test, common_norm=False, fill=True, alpha=0.3)\n",
    "    sns.kdeplot(data=errors, x=feature, hue=errors['Actual'], common_norm=False, fill=True, alpha=0.7, linestyle='--')\n",
    "    plt.title(f'Feature Distribution with Misclassifications Highlighted: {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend(title='Class', labels=['Non-Fraud', 'Fraud', 'Misclassified Non-Fraud', 'Misclassified Fraud'])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ca968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering - Function-based (no custom class)\n",
    "import numpy as np\n",
    "\n",
    "def feature_engineering(X):\n",
    "    X_fe = X.copy()\n",
    "    # Log transformations\n",
    "    X_fe['Amount_Log'] = np.log1p(X_fe['Amount'])\n",
    "    X_fe['Time_Log'] = np.log1p(X_fe['Time'])\n",
    "    # Add polynomial and interaction features for selected columns\n",
    "    candidate_features = ['V14', 'V12', 'V10', 'V17', 'V11', 'V4', 'V16']\n",
    "    for feature in candidate_features[:3]:\n",
    "        if feature in X_fe.columns:\n",
    "            X_fe[f'{feature}_squared'] = X_fe[feature] ** 2\n",
    "    if len(candidate_features) >= 2:\n",
    "        feat1 = candidate_features[0]\n",
    "        feat2 = candidate_features[1]\n",
    "        if feat1 in X_fe.columns and feat2 in X_fe.columns:\n",
    "            X_fe[f'{feat1}_x_{feat2}'] = X_fe[feat1] * X_fe[feat2]\n",
    "    return X_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dd2b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved model pipeline with function-based feature engineering\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "X = X.copy()\n",
    "y = y.copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply feature engineering function to training and test data\n",
    "X_train_fe = feature_engineering(X_train)\n",
    "X_test_fe = feature_engineering(X_test)\n",
    "\n",
    "# Get numeric features after feature engineering\n",
    "numeric_features = X_train_fe.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"\\nNumeric features after feature engineering: {len(numeric_features)} features\")\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ])\n",
    "\n",
    "# Logistic Regression Pipeline with FunctionTransformer\n",
    "log_clf = Pipeline(steps=[\n",
    "    ('feature_engineering', FunctionTransformer(feature_engineering)),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(solver='liblinear', max_iter=1000))\n",
    "])\n",
    "\n",
    "# Random Forest Pipeline with FunctionTransformer\n",
    "rf_clf = Pipeline(steps=[\n",
    "    ('feature_engineering', FunctionTransformer(feature_engineering)),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# XGBoost Pipeline with FunctionTransformer\n",
    "xb_clf = Pipeline(steps=[\n",
    "    ('feature_engineering', FunctionTransformer(feature_engineering)),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', xgb.XGBClassifier(random_state=42, n_jobs=1))\n",
    "])\n",
    "\n",
    "# Create Voting Classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('logistic', log_clf),\n",
    "    ('random_forest', rf_clf),\n",
    "    ('xgboost', xb_clf)\n",
    "], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80ef565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning and evaluation (function-based pipeline)\n",
    "\n",
    "# RandomizedSearch parameter grid\n",
    "param_dist_random = {\n",
    "    'logistic__classifier__C': uniform(0.1, 5),\n",
    "    'logistic__classifier__class_weight': ['balanced', {0: 1, 1: 20}],\n",
    "    'random_forest__classifier__n_estimators': randint(50, 150),\n",
    "    'random_forest__classifier__class_weight': ['balanced', 'balanced_subsample'],\n",
    "    'xgboost__classifier__n_estimators': randint(50, 150),\n",
    "    'xgboost__classifier__max_depth': randint(3, 7),\n",
    "    'xgboost__classifier__learning_rate': uniform(0.05, 0.2),\n",
    "    'xgboost__classifier__scale_pos_weight': [25, 50, 75]\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "# RandomizedSearch - broad exploration\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=voting_clf,\n",
    "    param_distributions=param_dist_random,\n",
    "    n_iter=10,\n",
    "    scoring='recall',\n",
    "    cv=skf,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Running RandomizedSearch...\")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_model_random = random_search.best_estimator_\n",
    "y_pred_random = best_model_random.predict(X_test)\n",
    "y_proba_random = best_model_random.predict_proba(X_test)[:, 1]\n",
    "\n",
    "report_random = classification_report(y_test, y_pred_random, output_dict=True)\n",
    "recall_random = report_random['1']['recall']\n",
    "f1_random = report_random['1']['f1-score']\n",
    "precision_random = report_random['1']['precision']\n",
    "\n",
    "print(f\"\\nRandomizedSearch Results:\")\n",
    "print(f\"Recall: {recall_random:.4f} | F1: {f1_random:.4f} | Precision: {precision_random:.4f}\")\n",
    "print(f\"Best params: {random_search.best_params_}\")\n",
    "\n",
    "# BayesianSearch and final evaluation would follow similarly as before\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Extract best values\n",
    "best_C = best_params.get('logistic__classifier__C', 1.0)\n",
    "best_rf_n_est = best_params.get('random_forest__classifier__n_estimators', 100)\n",
    "best_xgb_n_est = best_params.get('xgboost__classifier__n_estimators', 100)\n",
    "best_xgb_depth = best_params.get('xgboost__classifier__max_depth', 5)\n",
    "best_xgb_lr = best_params.get('xgboost__classifier__learning_rate', 0.1)\n",
    "best_scale_pos = best_params.get('xgboost__classifier__scale_pos_weight', 50)\n",
    "\n",
    "# Build narrow ranges around best parameters\n",
    "bayesian_param_dist = {\n",
    "    'logistic__classifier__C': Real(max(0.01, best_C * 0.5), min(10, best_C * 2), prior='log-uniform'),\n",
    "    'logistic__classifier__class_weight': Categorical(['balanced']),\n",
    "    'random_forest__classifier__n_estimators': Integer(max(50, best_rf_n_est - 30), min(200, best_rf_n_est + 30)),\n",
    "    'random_forest__classifier__class_weight': Categorical(['balanced', 'balanced_subsample']),\n",
    "    'xgboost__classifier__n_estimators': Integer(max(50, best_xgb_n_est - 30), min(200, best_xgb_n_est + 30)),\n",
    "    'xgboost__classifier__max_depth': Integer(max(2, best_xgb_depth - 2), min(10, best_xgb_depth + 2)),\n",
    "    'xgboost__classifier__learning_rate': Real(max(0.01, best_xgb_lr * 0.5), min(0.3, best_xgb_lr * 2), prior='log-uniform'),\n",
    "    'xgboost__classifier__scale_pos_weight': Integer(max(20, best_scale_pos - 25), min(150, best_scale_pos + 25))\n",
    "}\n",
    "\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=voting_clf,\n",
    "    search_spaces=bayesian_param_dist,\n",
    "    n_iter=15,\n",
    "    scoring='recall',\n",
    "    cv=skf,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nRunning Bayesian Optimization...\")\n",
    "bayes_search.fit(X_train, y_train)\n",
    "\n",
    "best_model_bayes = bayes_search.best_estimator_\n",
    "y_pred_bayes = best_model_bayes.predict(X_test)\n",
    "y_proba_bayes = best_model_bayes.predict_proba(X_test)[:, 1]\n",
    "\n",
    "report_bayes = classification_report(y_test, y_pred_bayes, output_dict=True)\n",
    "recall_bayes = report_bayes['1']['recall']\n",
    "f1_bayes = report_bayes['1']['f1-score']\n",
    "precision_bayes = report_bayes['1']['precision']\n",
    "\n",
    "# Final Comparison\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Metric':<15} {'Random':<12} {'Bayesian':<12} {'Δ':<10}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"{'Recall':<15} {recall_random:<12.4f} {recall_bayes:<12.4f} {recall_bayes-recall_random:+.4f}\")\n",
    "print(f\"{'F1-Score':<15} {f1_random:<12.4f} {f1_bayes:<12.4f} {f1_bayes-f1_random:+.4f}\")\n",
    "print(f\"{'Precision':<15} {precision_random:<12.4f} {precision_bayes:<12.4f} {precision_bayes-precision_random:+.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nConfusion Matrix (Bayesian):\")\n",
    "print(confusion_matrix(y_test, y_pred_bayes))\n",
    "print(\"\\nClassification Report (Bayesian):\")\n",
    "print(classification_report(y_test, y_pred_bayes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffd58d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Serialization and Versioning (function-based pipeline)\n",
    "import joblib\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Create models directory\n",
    "models_dir = Path('models')\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def save_model(model, name, metrics, params, description=''):\n",
    "    \"\"\"\n",
    "    Save model with metadata in a simple, organized way.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : trained model\n",
    "    name : str (e.g., 'voting_random' or 'voting_bayesian')\n",
    "    metrics : dict with recall, f1, precision\n",
    "    params : dict of hyperparameters\n",
    "    description : str\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # Save model\n",
    "    model_file = models_dir / f'{name}_{timestamp}.pkl'\n",
    "    joblib.dump(model, model_file, compress=3)\n",
    "    \n",
    "    # Save metadata alongside\n",
    "    metadata = {\n",
    "        'name': name,\n",
    "        'timestamp': timestamp,\n",
    "        'metrics': metrics,\n",
    "        'hyperparameters': params,\n",
    "        'description': description,\n",
    "        'model_file': str(model_file)\n",
    "    }\n",
    "    \n",
    "    metadata_file = models_dir / f'{name}_{timestamp}_info.json'\n",
    "    with open(metadata_file, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\" Saved: {name}\")\n",
    "    print(f\"  Model: {model_file.name}\")\n",
    "    print(f\"  Metrics: Recall={metrics['recall']:.4f}, F1={metrics['f1']:.4f}\")\n",
    "    \n",
    "    return str(model_file)\n",
    "\n",
    "def list_saved_models():\n",
    "    \"\"\"List all saved models.\"\"\"\n",
    "    model_files = sorted(models_dir.glob('*.pkl'))\n",
    "    \n",
    "    if not model_files:\n",
    "        print(\"No saved models found.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SAVED MODELS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for model_file in model_files:\n",
    "        info_file = str(model_file).replace('.pkl', '_info.json')\n",
    "        if Path(info_file).exists():\n",
    "            with open(info_file, 'r') as f:\n",
    "                info = json.load(f)\n",
    "            print(f\"\\n{info['name']} ({info['timestamp']})\")\n",
    "            print(f\"  Recall: {info['metrics']['recall']:.4f}\")\n",
    "            print(f\"  F1: {info['metrics']['f1']:.4f}\")\n",
    "            print(f\"  Precision: {info['metrics']['precision']:.4f}\")\n",
    "            print(f\"  Description: {info['description']}\")\n",
    "        else:\n",
    "            print(f\"\\n{model_file.name} (no metadata)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Save RandomizedSearch model\n",
    "save_model(\n",
    "    model=best_model_random,\n",
    "    name='voting_random',\n",
    "    metrics={'recall': recall_random, 'f1': f1_random, 'precision': precision_random},\n",
    "    params=random_search.best_params_,\n",
    "    description='Voting classifier with RandomizedSearch (function-based pipeline)'\n",
    ")\n",
    "\n",
    "# Save Bayesian model\n",
    "save_model(\n",
    "    model=best_model_bayes,\n",
    "    name='voting_bayesian',\n",
    "    metrics={'recall': recall_bayes, 'f1': f1_bayes, 'precision': precision_bayes},\n",
    "    params=bayes_search.best_params_,\n",
    "    description='Voting classifier with Bayesian optimization (function-based pipeline)'\n",
    ")\n",
    "\n",
    "# List all saved models\n",
    "list_saved_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91b2825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
