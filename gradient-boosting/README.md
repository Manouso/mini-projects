# Gradient Boosting

This project demonstrates how to train and evaluate a **GradientBoostingClassifier** using scikit-learn.

---

## Objectives

- Training a GradientBoostingClassifier.
- Learn why Boosting performs so well and compare it with RandomForestClassifier.
- Using Pipelines for preprocessing and modeling.
- Extracting and visualizing **feature importances**.
- Evaluating  performance with accuracy / confusion matrix.

---

## Project Structure

- **gradient-boosting/**
  - `gradient_boosting.ipynb` - Notebook
  - `heart.csv` - Dataset
  - `requirements.txt` — Requirements  
  - `README.md` — Project overview

---

## Dataset

[Heart Failure Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction)

This dataset contains 918 patient records, each with 11 clinical features that are commonly used in cardiovascular diagnostics.
The goal is to predict whether a patient is likely to develop heart disease based on medical measurements, lifestyle indicators, and symptoms.

---

## Requirements

```bash
pip install -r requirements.txt
```
---

## Insights