{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c82c004d",
   "metadata": {},
   "source": [
    "# Model Stacking for Heart Disease Prediction\n",
    "\n",
    "## Project Overview\n",
    "This notebook demonstrates an advanced **ensemble stacking** approach for heart disease prediction. We combine multiple base learners (XGBoost, Random Forest, Logistic Regression) with a meta-learner to achieve superior performance.\n",
    "\n",
    "### Key Concepts:\n",
    "- **Stacking**: Combining predictions from multiple models using a meta-learner\n",
    "- **Feature Engineering**: Creating domain-specific cardiovascular features\n",
    "- **Pipeline Architecture**: Preventing data leakage and ensuring reproducibility\n",
    "- **Hyperparameter Tuning**: Optimizing all model components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab2496d",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import all necessary libraries for data manipulation, modeling, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0f878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Machine Learning - Model Selection and Validation\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold, cross_val_score\n",
    "\n",
    "# Machine Learning - Models\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Machine Learning - Preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "from sklearn.metrics import matthews_corrcoef, cohen_kappa_score, log_loss\n",
    "\n",
    "# Machine Learning - Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, \n",
    "    roc_auc_score, roc_curve, precision_recall_curve, auc,\n",
    "    log_loss, matthews_corrcoef, cohen_kappa_score,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0a1409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('../datasets/heart.csv')\n",
    "df = data.copy()\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset Shape:\", data.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(data.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "data.info()\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "print(\"\\nTarget Distribution:\")\n",
    "print(data['HeartDisease'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e9bef0",
   "metadata": {},
   "source": [
    "### Load and Explore Dataset\n",
    "Load the heart disease dataset and display basic information about its structure, missing values, and target distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d883453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data patterns\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "colors = ['green', 'red']\n",
    "\n",
    "# Target distribution\n",
    "sns.countplot(x='HeartDisease', data=data, palette=colors, ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Heart Disease Distribution')\n",
    "\n",
    "# Exercise Angina\n",
    "sns.countplot(x='ExerciseAngina', hue='HeartDisease', data=data, palette=colors, ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Exercise Angina by Heart Disease')\n",
    "\n",
    "# Resting ECG\n",
    "sns.countplot(x='RestingECG', hue='HeartDisease', data=data, palette=colors, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Resting ECG by Heart Disease')\n",
    "\n",
    "# Chest Pain Type\n",
    "sns.countplot(x='ChestPainType', hue='HeartDisease', data=data, palette=colors, ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Chest Pain Type by Heart Disease')\n",
    "\n",
    "# Sex distribution\n",
    "sns.countplot(x='Sex', hue='HeartDisease', data=data, palette=colors, ax=axes[2, 0])\n",
    "axes[2, 0].set_title('Sex by Heart Disease')\n",
    "\n",
    "# Correlation heatmap\n",
    "corr = data.select_dtypes(include=[np.number]).corr()\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', ax=axes[2, 1])\n",
    "axes[2, 1].set_title('Correlation Heatmap')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bdff19",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis Visualizations\n",
    "Create visualizations to understand the relationships between features and heart disease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29735cc",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Exploratory Analysis\n",
    "\n",
    "Load the Heart Disease dataset and visualize key patterns including target distribution, feature relationships, and correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9d9ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature types\n",
    "binary_features = ['Sex', 'ExerciseAngina']\n",
    "multi_categorical_features = ['ChestPainType', 'RestingECG', 'ST_Slope']\n",
    "numeric_features = ['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR', 'Oldpeak']\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "numerical_pipeline = Pipeline([('scaler', StandardScaler())])\n",
    "binary_pipeline = Pipeline([('ordinal', OrdinalEncoder())])\n",
    "categorical_pipeline = Pipeline([('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_pipeline, numeric_features),\n",
    "    ('bin', binary_pipeline, binary_features),\n",
    "    ('cat', categorical_pipeline, multi_categorical_features)\n",
    "])\n",
    "\n",
    "# Split data BEFORE any preprocessing (prevents leakage)\n",
    "X = df.drop('HeartDisease', axis=1)\n",
    "y = df['HeartDisease']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Define base learners\n",
    "base_learners = [\n",
    "    ('xgb', XGBClassifier(random_state=42, eval_metric='logloss')),\n",
    "    ('rf', RandomForestClassifier(random_state=42)),\n",
    "    ('lr', LogisticRegression(solver='liblinear', random_state=42))\n",
    "]\n",
    "\n",
    "# Create stacking classifier with out-of-fold predictions (prevents leakage)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=base_learners,\n",
    "    final_estimator=LogisticRegression(solver='liblinear', random_state=42),\n",
    "    passthrough=False,  # No leakage: meta-learner only sees base model predictions\n",
    "    cv=skf,             # Uses out-of-fold predictions (no leakage)\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Build and train pipeline (preprocessing inside pipeline prevents leakage)\n",
    "baseline_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),  # Fits on train, transforms test\n",
    "    ('classifier', stacking_clf)\n",
    "])\n",
    "\n",
    "print(\"Training baseline model...\")\n",
    "baseline_pipeline.fit(X_train, y_train)  # Only train data used for fitting\n",
    "\n",
    "# Evaluate\n",
    "y_pred = baseline_pipeline.predict(X_test)\n",
    "y_proba = baseline_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"Baseline Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Baseline ROC-AUC: {roc_auc_score(y_test, y_proba):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cfe067",
   "metadata": {},
   "source": [
    "### Build Baseline Stacking Model\n",
    "Create preprocessing pipelines and train the baseline stacking classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e8c7cd",
   "metadata": {},
   "source": [
    "## 4. Advanced Feature Engineering with Overfitting Prevention\n",
    "\n",
    "Create comprehensive cardiovascular-specific features while implementing regularization techniques to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f673e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(X):\n",
    "    \"\"\"\n",
    "    Simple feature engineering for beginners - only 3 features!\n",
    "    Focus: Basic interpretable features that make medical sense\n",
    "    No leakage: stateless transformation (no fitting required)\n",
    "    \"\"\"\n",
    "    X = X.copy()  # Avoid modifying original data\n",
    "\n",
    "    # 1. Heart Rate Reserve - measures cardiac capacity\n",
    "    # Formula: Maximum theoretical HR - actual max HR achieved\n",
    "    # Lower values = less cardiac reserve = higher risk\n",
    "    X['Heart_Rate_Reserve'] = 220 - X['Age'] - X['MaxHR']\n",
    "    \n",
    "    # 2. Age-Cholesterol interaction - captures combined risk\n",
    "    # Older age + high cholesterol = exponentially higher risk\n",
    "    X['Age_Chol_Product'] = X['Age'] * X['Cholesterol']\n",
    "    \n",
    "    # 3. Blood Pressure Risk Score - normalized BP indicator\n",
    "    # Normal BP ~120, so divide by 120 to get risk ratio\n",
    "    X['BP_Risk_Score'] = X['RestingBP'] / 120\n",
    "    \n",
    "    return X\n",
    "\n",
    "# Create feature engineering transformer\n",
    "feature_engineer = FunctionTransformer(engineer_features, validate=False)\n",
    "\n",
    "# List engineered features (only 3 features!)\n",
    "engineered_feature_names = [\n",
    "    'Heart_Rate_Reserve',    # Cardiac capacity\n",
    "    'Age_Chol_Product',      # Combined age-cholesterol risk\n",
    "    'BP_Risk_Score'          # Normalized blood pressure\n",
    "]\n",
    "\n",
    "# Complete feature list: 6 original + 3 engineered = 9 total\n",
    "numeric_features_fe = numeric_features + engineered_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e91644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pipeline with feature engineering and regularization to prevent overfitting\n",
    "numerical_pipeline_fe = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor_fe = ColumnTransformer([\n",
    "    ('num', numerical_pipeline_fe, numeric_features_fe),\n",
    "    ('bin', binary_pipeline, binary_features),\n",
    "    ('cat', categorical_pipeline, multi_categorical_features)\n",
    "])\n",
    "\n",
    "# 1. XGBoost with regularization\n",
    "xgb_regularized = XGBClassifier(\n",
    "    random_state=42, \n",
    "    eval_metric='logloss',\n",
    "    reg_alpha=0.1,      # L1 regularization\n",
    "    reg_lambda=1.0,     # L2 regularization\n",
    "    max_depth=4,        # Limit tree depth\n",
    "    min_child_weight=3, # Require more samples per leaf\n",
    "    subsample=0.8,      # Sample 80% of data\n",
    "    colsample_bytree=0.8  # Use 80% of features\n",
    ")\n",
    "\n",
    "# 2. RandomForest with regularization\n",
    "rf_regularized = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=15,           # Limit tree depth\n",
    "    min_samples_split=20,   # Require more samples to split\n",
    "    min_samples_leaf=4,     # Require more samples per leaf\n",
    "    max_features='sqrt',    # Limit features per tree\n",
    "    max_samples=0.8         # Bootstrap 80% of data\n",
    ")\n",
    "\n",
    "# 3. Logistic Regression with strong regularization\n",
    "lr_regularized = LogisticRegression(\n",
    "    solver='liblinear',\n",
    "    random_state=42,\n",
    "    C=0.1,              # Strong regularization (inverse)\n",
    "    penalty='l2',       # L2 regularization\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "# Regularized base learners\n",
    "base_learners_fe = [\n",
    "    ('xgb', xgb_regularized),\n",
    "    ('rf', rf_regularized),\n",
    "    ('lr', lr_regularized)\n",
    "]\n",
    "\n",
    "# Stacking with regularized meta-learner (no leakage)\n",
    "stacking_clf_fe = StackingClassifier(\n",
    "    estimators=base_learners_fe,\n",
    "    final_estimator=LogisticRegression(\n",
    "        solver='liblinear', \n",
    "        random_state=42,\n",
    "        C=0.5,          # Moderate regularization for meta-learner\n",
    "        penalty='l2'\n",
    "    ),\n",
    "    passthrough=False,   # No leakage: meta-learner only sees base predictions\n",
    "    cv=skf,              # Out-of-fold predictions prevent leakage\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Complete pipeline (feature engineering inside pipeline prevents leakage)\n",
    "complete_pipeline = Pipeline([\n",
    "    ('feature_engineering', feature_engineer),  # Applied after split\n",
    "    ('preprocessor', preprocessor_fe),          # Fits on train only\n",
    "    ('classifier', stacking_clf_fe)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91b176f",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Optimization with Overfitting Prevention\n",
    "\n",
    "Optimize model parameters using RandomizedSearchCV while maintaining regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a810d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified parameter grid focused on key regularization parameters\n",
    "param_grid = {\n",
    "    # Meta-learner regularization\n",
    "    'classifier__final_estimator__C': [0.1, 0.5, 1.0],\n",
    "    \n",
    "    # XGBoost parameters\n",
    "    'classifier__xgb__n_estimators': [100, 200],\n",
    "    'classifier__xgb__max_depth': [3, 4, 5],\n",
    "    'classifier__xgb__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'classifier__xgb__reg_alpha': [0, 0.1, 0.5],\n",
    "    'classifier__xgb__reg_lambda': [1.0, 2.0],\n",
    "    \n",
    "    # RandomForest parameters\n",
    "    'classifier__rf__n_estimators': [100, 200],\n",
    "    'classifier__rf__max_depth': [10, 15, 20],\n",
    "    'classifier__rf__min_samples_split': [5, 10],\n",
    "    'classifier__rf__min_samples_leaf': [2, 4],\n",
    "    \n",
    "    # Logistic Regression regularization\n",
    "    'classifier__lr__C': [0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Run hyperparameter search (no leakage: CV done only on train set)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=complete_pipeline,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,  # Balanced number of iterations\n",
    "    scoring='roc_auc',\n",
    "    cv=skf,     # Cross-validation on training data only\n",
    "    verbose=0,  # 0: silent, 1: progress bar, 2: detailed output\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "time_start = time.time()\n",
    "random_search.fit(X_train, y_train)  # Test set never seen during tuning\n",
    "time_end = time.time()\n",
    "time_elapsed = time_end - time_start\n",
    "\n",
    "print(f\"Hyperparameter tuning completed in {time_elapsed:.2f} seconds\")\n",
    "print(f\"Best CV ROC-AUC: {random_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bdf52b",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation and Performance Analysis\n",
    "\n",
    "Comprehensive evaluation of the optimized model with multiple metrics and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab1727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model and predictions\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred_opt = best_model.predict(X_test)\n",
    "y_proba_opt = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy_opt = accuracy_score(y_test, y_pred_opt)\n",
    "precision_opt = precision_score(y_test, y_pred_opt)\n",
    "recall_opt = recall_score(y_test, y_pred_opt)\n",
    "f1_opt = f1_score(y_test, y_pred_opt)\n",
    "roc_auc_opt = roc_auc_score(y_test, y_proba_opt)\n",
    "mcc_opt = matthews_corrcoef(y_test, y_pred_opt)\n",
    "kappa_opt = cohen_kappa_score(y_test, y_pred_opt)\n",
    "logloss_opt = log_loss(y_test, y_proba_opt)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_opt = confusion_matrix(y_test, y_pred_opt)\n",
    "\n",
    "# PR curve\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_proba_opt)\n",
    "pr_auc_opt = auc(recall_vals, precision_vals)\n",
    "\n",
    "# Display results\n",
    "print(\"Optimized Model Evaluation\")\n",
    "print(f\"Accuracy:  {accuracy_opt:.4f}\")\n",
    "print(f\"Precision: {precision_opt:.4f}\")\n",
    "print(f\"Recall:    {recall_opt:.4f}\")\n",
    "print(f\"F1-Score:  {f1_opt:.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_opt:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaeb730",
   "metadata": {},
   "source": [
    "### Evaluate Optimized Model\n",
    "Calculate comprehensive performance metrics for the tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42951d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance visualizations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion Matrix\n",
    "sns.heatmap(cm_opt, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Actual', fontsize=12)\n",
    "axes[0].set_xlabel('Predicted', fontsize=12)\n",
    "\n",
    "# ROC Curve\n",
    "fpr_opt, tpr_opt, _ = roc_curve(y_test, y_proba_opt)\n",
    "axes[1].plot(fpr_opt, tpr_opt, label=f'ROC-AUC = {roc_auc_opt:.3f}', linewidth=2.5, color='coral')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', alpha=0.3, label='Random')\n",
    "axes[1].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[1].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[1].set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831abf81",
   "metadata": {},
   "source": [
    "### Visualize Model Performance\n",
    "Create comprehensive visualizations comparing baseline and optimized models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25236c59",
   "metadata": {},
   "source": [
    "## ðŸ“Š Baseline vs Optimized Comparison\n",
    "Compare performance between baseline and optimized models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcaefc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate baseline metrics\n",
    "y_pred_baseline = baseline_pipeline.predict(X_test)\n",
    "y_proba_baseline = baseline_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "baseline_metrics = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_baseline),\n",
    "    'Precision': precision_score(y_test, y_pred_baseline),\n",
    "    'Recall': recall_score(y_test, y_pred_baseline),\n",
    "    'F1-Score': f1_score(y_test, y_pred_baseline),\n",
    "    'ROC-AUC': roc_auc_score(y_test, y_proba_baseline),\n",
    "    'MCC': matthews_corrcoef(y_test, y_pred_baseline),\n",
    "}\n",
    "\n",
    "optimized_metrics = {\n",
    "    'Accuracy': accuracy_opt,\n",
    "    'Precision': precision_opt,\n",
    "    'Recall': recall_opt,\n",
    "    'F1-Score': f1_opt,\n",
    "    'ROC-AUC': roc_auc_opt,\n",
    "    'MCC': mcc_opt,\n",
    "}\n",
    "\n",
    "# Create simplified comparison visualization\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# ROC Curves Comparison\n",
    "fpr_baseline, tpr_baseline, _ = roc_curve(y_test, y_proba_baseline)\n",
    "fpr_opt, tpr_opt, _ = roc_curve(y_test, y_proba_opt)\n",
    "\n",
    "ax.plot(fpr_baseline, tpr_baseline, label=f'Baseline (AUC={baseline_metrics[\"ROC-AUC\"]:.3f})', \n",
    "        color='skyblue', linewidth=2.5)\n",
    "ax.plot(fpr_opt, tpr_opt, label=f'Optimized (AUC={optimized_metrics[\"ROC-AUC\"]:.3f})', \n",
    "        color='coral', linewidth=2.5)\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Random', linewidth=1.5, alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12, fontweight='bold')\n",
    "ax.set_title('ROC Curve: Baseline vs Optimized', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.legend(loc='lower right', fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print comparison summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Model Performance Comparison\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n{'Metric':<15} {'Baseline':>12} {'Optimized':>12} {'Change':>12}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "metrics_to_show = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC', 'MCC']\n",
    "for metric in metrics_to_show:\n",
    "    base_val = baseline_metrics[metric]\n",
    "    opt_val = optimized_metrics[metric]\n",
    "    change = opt_val - base_val\n",
    "    print(f\"{metric:<15} {base_val:>12.4f} {opt_val:>12.4f} {change:>+12.4f}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nâœ… Optimized model ROC-AUC: {optimized_metrics['ROC-AUC']:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b574d9",
   "metadata": {},
   "source": [
    "The comparison shows the impact of hyperparameter tuning and feature engineering. The visualization includes metric comparisons, ROC curves, precision-recall curves, and percentage improvements for each metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992c95cb",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis\n",
    "\n",
    "Analyze which features contribute most to predictions using meta-learner coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f94069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from Random Forest base model\n",
    "rf_model = best_model.named_steps['classifier'].named_estimators_['rf']\n",
    "xgb_model = best_model.named_steps['classifier'].named_estimators_['xgb']\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "preprocessor_opt = best_model.named_steps['preprocessor']\n",
    "\n",
    "# Build complete feature names\n",
    "all_feature_names = []\n",
    "all_feature_names.extend(numeric_features_fe)  # All numeric features (original + engineered)\n",
    "all_feature_names.extend(binary_features)\n",
    "\n",
    "# Get one-hot encoded categorical feature names\n",
    "onehot_features = preprocessor_opt.named_transformers_['cat'].named_steps['onehot']\n",
    "cat_feature_names = onehot_features.get_feature_names_out(multi_categorical_features)\n",
    "all_feature_names.extend(cat_feature_names)\n",
    "\n",
    "# Get feature importances from both models\n",
    "rf_importances = rf_model.feature_importances_\n",
    "xgb_importances = xgb_model.feature_importances_\n",
    "\n",
    "# Average the importances\n",
    "avg_importances = (rf_importances + xgb_importances) / 2\n",
    "\n",
    "# Create dataframe\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'RF_Importance': rf_importances,\n",
    "    'XGB_Importance': xgb_importances,\n",
    "    'Avg_Importance': avg_importances\n",
    "}).sort_values('Avg_Importance', ascending=False)\n",
    "\n",
    "# Visualize top 20 features\n",
    "top_20 = feature_importance_df.head(20)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "y_pos = np.arange(len(top_20))\n",
    "\n",
    "ax.barh(y_pos, top_20['Avg_Importance'], color='steelblue', alpha=0.7)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(top_20['Feature'], fontsize=10)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Average Importance (RF + XGBoost)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Top 20 Feature Importances', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.grid(alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels\n",
    "for i, (idx, row) in enumerate(top_20.iterrows()):\n",
    "    ax.text(row['Avg_Importance'], i, f' {row[\"Avg_Importance\"]:.4f}', \n",
    "            va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1316d6",
   "metadata": {},
   "source": [
    "### Feature Importance Visualization\n",
    "Visualize which features contribute most to the model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2ab5ff",
   "metadata": {},
   "source": [
    "## 8. Prediction Confidence and Sample Analysis\n",
    "\n",
    "Analyze model confidence distribution and examine sample predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fd988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get confidence scores\n",
    "if y_proba_opt.ndim == 1:\n",
    "    confidence_scores = np.abs(y_proba_opt - 0.5) + 0.5\n",
    "else:\n",
    "    confidence_scores = np.max(y_proba_opt, axis=1)\n",
    "\n",
    "# Calculate confidence distribution\n",
    "very_high = (confidence_scores >= 0.95).sum()\n",
    "high = ((confidence_scores >= 0.8) & (confidence_scores < 0.95)).sum()\n",
    "moderate = ((confidence_scores >= 0.6) & (confidence_scores < 0.8)).sum()\n",
    "low = (confidence_scores < 0.6).sum()\n",
    "\n",
    "print(\"Confidence Distribution:\")\n",
    "print(f\"Very High (â‰¥95%): {very_high} ({very_high/len(confidence_scores)*100:.1f}%)\")\n",
    "print(f\"High (80-95%): {high} ({high/len(confidence_scores)*100:.1f}%)\")\n",
    "print(f\"Moderate (60-80%): {moderate} ({moderate/len(confidence_scores)*100:.1f}%)\")\n",
    "print(f\"Low (<60%): {low} ({low/len(confidence_scores)*100:.1f}%)\")\n",
    "\n",
    "# Sample predictions\n",
    "sample_idx = np.random.choice(len(X_test), 6, replace=False)\n",
    "print(\"\\nSample Predictions:\")\n",
    "for i in sample_idx:\n",
    "    actual = y_test.iloc[i]\n",
    "    pred = y_pred_opt[i]\n",
    "    prob = y_proba_opt[i, 1] if y_proba_opt.ndim > 1 else y_proba_opt[i]\n",
    "    status = \"âœ“\" if pred == actual else \"âœ—\"\n",
    "    print(f\"{status} Patient {i}: Pred={pred}, Prob={prob:.1%}, Actual={actual}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Confidence distribution\n",
    "conf_labels = ['Low', 'Moderate', 'High', 'Very High']\n",
    "conf_counts = [low, moderate, high, very_high]\n",
    "axes[0].bar(conf_labels, conf_counts, color=['red', 'orange', 'lightgreen', 'green'], alpha=0.7)\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Confidence Distribution')\n",
    "axes[0].grid(alpha=0.3, axis='y')\n",
    "\n",
    "# Confidence by class\n",
    "conf_class0 = confidence_scores[y_pred_opt == 0]\n",
    "conf_class1 = confidence_scores[y_pred_opt == 1]\n",
    "bp = axes[1].boxplot([conf_class0, conf_class1], labels=['No Disease', 'Disease'], patch_artist=True)\n",
    "bp['boxes'][0].set_facecolor('lightblue')\n",
    "bp['boxes'][1].set_facecolor('lightcoral')\n",
    "axes[1].set_ylabel('Confidence Score')\n",
    "axes[1].set_title('Confidence by Predicted Class')\n",
    "axes[1].grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98b1d36",
   "metadata": {},
   "source": [
    "### Confidence Analysis and Sample Predictions\n",
    "Analyze prediction confidence levels and examine specific sample predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
