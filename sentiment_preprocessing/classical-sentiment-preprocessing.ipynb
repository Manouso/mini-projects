{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e3d9e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfb1f42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Download the English model for spaCy\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "\n",
    "# Load Dataset\n",
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "print(df.head())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0a4fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable componenents to speed up processing and focus on tokenization and lemmatization\n",
    "nlp = spacy.load(\"en_core_web_sm\",disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# Process reviews efficiently using streaming (generator) to avoid memory overflow on large datasets\n",
    "def preprocess_dataset(texts):\n",
    "    # Remove HTML tags first\n",
    "    texts = [re.sub(r'<[^>]+>', '', text) for text in texts]\n",
    "    preprocessed_text = []\n",
    "    # nlp.pipe processes texts as a stream and is much faster than applying nlp to each text individually\n",
    "    for doc in nlp.pipe(texts, batch_size=1000):\n",
    "        # Extract lemmas for non-stop, non-punct, alphabetic tokens, lowercased\n",
    "        tokens = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct and token.is_alpha]\n",
    "        preprocessed_text.append(' '.join(tokens))\n",
    "    return preprocessed_text\n",
    "            \n",
    "\n",
    "# Display original and preprocessed text for the first few reviews to verify preprocessing\n",
    "# Note: Preprocessing will be done after train/test split to prevent data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5862ef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Vocabulary & Vectorizers\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Initialize vectorizers with n-gram support\n",
    "bow_vectorizer = CountVectorizer(ngram_range=(1, 2), min_df=5, max_features=5000) # ngram_range=(1,2) means unigrams + bigrams\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=5, max_features=5000) # min_df=5 ignores terms that appear in less than 5 documents (removes noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4165d49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 40000\n",
      "Test set size: 10000\n",
      "BoW Matrix Shape (train): (40000, 5000)\n",
      "TF-IDF Matrix Shape (train): (40000, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Vectorization Phase\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Encode labels first (positive = 1, negative = 0)\n",
    "df['label'] = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "\n",
    "# Split data into train/test (80/20) to prevent data leakage\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    df['review'], \n",
    "    df['label'], \n",
    "    test_size=0.2, \n",
    "    stratify=df['label'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Preprocess training and test sets separately\n",
    "X_train_text = preprocess_dataset(X_train_text)\n",
    "X_test_text = preprocess_dataset(X_test_text)\n",
    "\n",
    "# Fit vectorizers on training data only, then transform both sets\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train_text)\n",
    "X_test_bow = bow_vectorizer.transform(X_test_text)\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_text)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_text)\n",
    "\n",
    "print(f\"Training set size: {len(X_train_text)}\")\n",
    "print(f\"Test set size: {len(X_test_text)}\")\n",
    "print(f\"BoW Matrix Shape (train): {X_train_bow.shape}\")\n",
    "print(f\"TF-IDF Matrix Shape (train): {X_train_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f841783e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manousos Kirkinis\\torch\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Manousos Kirkinis\\torch\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Manousos Kirkinis\\torch\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Manousos Kirkinis\\torch\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Manousos Kirkinis\\torch\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Manousos Kirkinis\\torch\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Manousos Kirkinis\\torch\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Manousos Kirkinis\\torch\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Manousos Kirkinis\\torch\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Manousos Kirkinis\\torch\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Manousos Kirkinis\\torch\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Manousos Kirkinis\\torch\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Logistic Regression Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89      5000\n",
      "           1       0.88      0.90      0.89      5000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "[[4382  618]\n",
      " [ 517 4483]]\n",
      "ROC AUC: 0.9544\n",
      "TF-IDF Naive Bayes Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85      5000\n",
      "           1       0.84      0.87      0.85      5000\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "[[4155  845]\n",
      " [ 640 4360]]\n",
      "ROC AUC: 0.9282\n",
      "BoW Naive Bayes Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84      5000\n",
      "           1       0.84      0.85      0.85      5000\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "[[4190  810]\n",
      " [ 730 4270]]\n",
      "ROC AUC: 0.9123\n",
      "BoW Logistic Regression Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      5000\n",
      "           1       0.88      0.90      0.89      5000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "[[4364  636]\n",
      " [ 519 4481]]\n",
      "ROC AUC: 0.9482\n"
     ]
    }
   ],
   "source": [
    "# Training Pipeline with Cross-Validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "\n",
    "# Set up Stratified K-Fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "model_tfidf = LogisticRegressionCV(\n",
    "    max_iter=1000, \n",
    "    Cs=20, \n",
    "    solver='saga', \n",
    "    n_jobs=-1, \n",
    "    cv=skf,\n",
    "    random_state=42,\n",
    "    l1_ratios=(0,),\n",
    "    use_legacy_attributes=True\n",
    ")\n",
    "\n",
    "model_bow = LogisticRegressionCV(\n",
    "    max_iter=1000, \n",
    "    Cs=20, \n",
    "    solver='saga', \n",
    "    n_jobs=-1, \n",
    "    cv=skf,\n",
    "    random_state=42,\n",
    "    l1_ratios=(0,),\n",
    "    use_legacy_attributes=True\n",
    ")\n",
    "\n",
    "model_tfidf_alt = MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n",
    "model_bow_alt = MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n",
    "\n",
    "# Train all models on training set\n",
    "model_tfidf.fit(X_train_tfidf, y_train)\n",
    "model_tfidf_alt.fit(X_train_tfidf, y_train)\n",
    "model_bow_alt.fit(X_train_bow, y_train)\n",
    "model_bow.fit(X_train_bow, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_tfidf = model_tfidf.predict(X_test_tfidf)\n",
    "print(\"TF-IDF Logistic Regression Test Results:\")\n",
    "print(classification_report(y_test, y_pred_tfidf))\n",
    "print(confusion_matrix(y_test, y_pred_tfidf))\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, model_tfidf.predict_proba(X_test_tfidf)[:, 1]):.4f}\")\n",
    "\n",
    "y_pred_tfidf_alt = model_tfidf_alt.predict(X_test_tfidf)\n",
    "print(\"TF-IDF Naive Bayes Test Results:\")\n",
    "print(classification_report(y_test, y_pred_tfidf_alt))\n",
    "print(confusion_matrix(y_test, y_pred_tfidf_alt))\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, model_tfidf_alt.predict_proba(X_test_tfidf)[:, 1]):.4f}\")\n",
    "\n",
    "y_pred_bow_alt = model_bow_alt.predict(X_test_bow)\n",
    "print(\"BoW Naive Bayes Test Results:\")\n",
    "print(classification_report(y_test, y_pred_bow_alt))\n",
    "print(confusion_matrix(y_test, y_pred_bow_alt))\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, model_bow_alt.predict_proba(X_test_bow)[:, 1]):.4f}\")\n",
    "\n",
    "y_pred_bow = model_bow.predict(X_test_bow)\n",
    "print(\"BoW Logistic Regression Test Results:\")\n",
    "print(classification_report(y_test, y_pred_bow))\n",
    "print(confusion_matrix(y_test, y_pred_bow))\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, model_bow.predict_proba(X_test_bow)[:, 1]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "945ea82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models and vectorizers saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save all trained models and vectorizers for deployment\n",
    "with open('sentiment_models.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'tfidf_model': model_tfidf,\n",
    "        'tfidf_model_alt': model_tfidf_alt,\n",
    "        'bow_model': model_bow,\n",
    "        'bow_model_alt': model_bow_alt,\n",
    "        'tfidf_vectorizer': tfidf_vectorizer,\n",
    "        'bow_vectorizer': bow_vectorizer\n",
    "    }, f)\n",
    "\n",
    "print(\"All models and vectorizers saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
